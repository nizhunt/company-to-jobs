name: Daily Scrape

on:
  schedule:
    - cron: "0 8 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"
          cache: "pip"
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run scraper
        env:
          INPUT_CSV: "Account Information - 2024.csv"
          N8N_WEBHOOK_URL: ${{ secrets.N8N_WEBHOOK_URL }}
          N8N_WEBHOOK_TOKEN: ${{ secrets.N8N_WEBHOOK_TOKEN }}
          MAX_JOBS_PER_COMPANY: "50"
          MAX_TOTAL_JOBS: "1000"
        run: python3 scrape_jobs.py
      - name: Upload diff artifact
        uses: actions/upload-artifact@v4
        with:
          name: jobs_diff
          path: jobs_diff.csv
      - name: Commit updated base, diff, and zero CSVs
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add jobs_scraped.csv jobs_diff.csv jobs_zero.csv
          git diff --cached --quiet || git commit -m "daily scrape: update base CSV"
          git push
